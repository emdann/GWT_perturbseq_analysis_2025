{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2df04f9-4030-4cc1-9d4d-c5e5213e2066",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rzhu/miniconda3/envs/deseq/lib/python3.11/site-packages/scanpy/_utils/__init__.py:33: FutureWarning: `__version__` is deprecated, use `importlib.metadata.version('anndata')` instead.\n",
      "  from anndata import __version__ as anndata_version\n",
      "/Users/rzhu/miniconda3/envs/deseq/lib/python3.11/site-packages/scanpy/__init__.py:24: FutureWarning: `__version__` is deprecated, use `importlib.metadata.version('anndata')` instead.\n",
      "  if Version(anndata.__version__) >= Version(\"0.11.0rc2\"):\n",
      "/Users/rzhu/miniconda3/envs/deseq/lib/python3.11/site-packages/scanpy/readwrite.py:16: FutureWarning: `__version__` is deprecated, use `importlib.metadata.version('anndata')` instead.\n",
      "  if Version(anndata.__version__) >= Version(\"0.11.0rc2\"):\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import scanpy as sc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from joblib import Parallel, delayed\n",
    "import time\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import hdbscan\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.stats import hypergeom\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as mcolors \n",
    "import time\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "\n",
    "sys.path.append('../3_DE_analysis/')\n",
    "from DE_analysis_utils import *\n",
    "\n",
    "pd.set_option('display.max_rows', 100)\n",
    "sc.set_figure_params(figsize=(20, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8cd7504f-01ef-460e-a2d4-a19c6194abc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adata_de = sc.read_h5ad('../../../../3_expts/processed_data/CD4i_final//DE_results_all_confounders/CD4i_final.merged_DE_results_corrected.h5ad', backed='r')\n",
    "adata_final = sc.read_h5ad('../../../../3_expts/processed_data/analysis_largefiles/nde75ntotal50_varfiltered_simple_clustering.h5ad')#, backed='r')\n",
    "#de_by_guide = pd.read_csv('../3_DE_analysis/results/DE_by_guide.correlation_results.csv', index_col=0)\n",
    "#donor_robustness_summary = pd.read_csv('../3_DE_analysis/results/DE_donor_robustness_correlation_summary.csv', index_col=0)\n",
    "#de_summary_stats = pd.read_csv('../../../../3_expts/processed_data/CD4i_final/DE_results_all_confounders/DE_summary_stats_per_target_corrected.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36d12564-00f2-4d58-a81f-7f56324de203",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_cluster = len(adata_final.obs['hdbscan'].unique())\n",
    "cluster_name = []\n",
    "corr = []\n",
    "cluster_size = []\n",
    "cluster_gene_size = []\n",
    "cluster_member = []\n",
    "for i, cl in enumerate(adata_final.obs['hdbscan'].unique()):\n",
    "    df = pd.DataFrame(data=adata_final[adata_final.obs['hdbscan']==cl].layers['zscore'],\n",
    "                        index=adata_final[adata_final.obs['hdbscan']==cl].obs_names,\n",
    "                        columns=adata_final.var_names)\n",
    "    df_corr = df.T.corr()\n",
    "    np.fill_diagonal(df_corr.values, 0)\n",
    "    cluster_name.append(int(cl))\n",
    "    corr.append(np.mean(df_corr))\n",
    "    cluster_size.append(len(df))\n",
    "    cluster_gene_size.append(len(adata_final[adata_final.obs['hdbscan']==cl].obs.target_contrast_gene_name_corrected.unique()))\n",
    "    cluster_member.append(adata_final[adata_final.obs['hdbscan']==cl].obs.target_contrast_gene_name_corrected.unique().tolist())\n",
    "\n",
    "cluster_df = pd.DataFrame({'cluster': cluster_name,\n",
    "                           'intracluster_corr': corr,\n",
    "                           'cluster_size': cluster_size,\n",
    "                           'cluster_gene_size': cluster_gene_size,\n",
    "                           'cluster_member': cluster_member})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89b4bee8-96ed-445c-93e1-b9e854f06876",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gseapy\n",
    "from gseapy import Msigdb\n",
    "from gseapy import barplot, dotplot\n",
    "\n",
    "msig = Msigdb()\n",
    "kegg_gene_sets = msig.get_gmt(category= 'c2.cp.kegg_legacy', dbver=\"2025.1.Hs\")\n",
    "reactome_gene_sets = msig.get_gmt(category= 'c2.cp.reactome', dbver=\"2025.1.Hs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca878427-870a-460c-810e-5c44d248695c",
   "metadata": {},
   "outputs": [],
   "source": [
    "corum_df = pd.read_csv('../../../../2_files/enrichment_analysis/CORUM/corum_humanComplexes.txt', delimiter='\\t', index_col='complex_id')\n",
    "stringdb = pd.read_csv('../../../../2_files/enrichment_analysis/STRINGDB/9606.clusters.proteins.v12.0.txt.gz', delimiter='\\t', compression='gzip')\n",
    "protein_info = pd.read_csv('../../../../2_files/enrichment_analysis/STRINGDB/9606.protein.info.v12.0.txt.gz', delimiter='\\t', compression='gzip')\n",
    "cluster_info = pd.read_csv('../../../../2_files/enrichment_analysis/STRINGDB/9606.clusters.info.v12.0.txt.gz', delimiter='\\t', compression='gzip')\n",
    "stringdb_df = pd.merge(stringdb, protein_info, left_on='protein_id', right_on='#string_protein_id')\n",
    "stringdb_df = pd.merge(stringdb_df, cluster_info, left_on='cluster_id', right_on='cluster_id')\n",
    "stringdb_df = stringdb_df[stringdb_df.cluster_size<1000].copy()\n",
    "\n",
    "corum_complexes = {}\n",
    "for _, row in corum_df.iterrows():\n",
    "    complex_name = row['complex_name']\n",
    "    subunits = set(row['subunits_gene_name'].split(';'))\n",
    "    corum_complexes[complex_name] = subunits\n",
    "\n",
    "stringdb_complexes = {}\n",
    "for cluster_id in stringdb_df.cluster_id.unique():\n",
    "    stringdb_complexes[cluster_id] = set(stringdb_df[stringdb_df.cluster_id==cluster_id].preferred_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9cb31fda-a248-4d76-81ad-2116a93f201c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def assess_complex_enrichment(df, complexes, cluster_label, gene_name_label):\n",
    "    \"\"\"\n",
    "    Assess pathway/complex enrichment\n",
    "    \"\"\"\n",
    "    de_genes_per_cluster = {}\n",
    "    clusters = df[cluster_label].unique()\n",
    "    for cluster in clusters:\n",
    "        cluster_genes = df[df[cluster_label]==cluster][gene_name_label]\n",
    "        de_genes_per_cluster[cluster] = set(cluster_genes)\n",
    "\n",
    "    N = len(df[gene_name_label].unique())\n",
    "    \n",
    "    best_result = []\n",
    "    all_result = []\n",
    "    for cluster, de_genes in de_genes_per_cluster.items():\n",
    "        n = len(de_genes)\n",
    "        best_result_for_cluster = None # Initialize a variable to track the best result for this cluster\n",
    "        for complex_name, subunits in complexes.items():\n",
    "            K = len(subunits)\n",
    "            # Find the overlap between DE genes and complex subunits\n",
    "            overlap = de_genes.intersection(subunits)\n",
    "            k = len(overlap)\n",
    "            \n",
    "            # Calculate the p-value\n",
    "            if (n > 0 and K > 0) and (k > 1): # Avoid division by zero or trivial cases\n",
    "                pval = hypergeom.sf(k - 1, N, K, n) # sf is survival function\n",
    "                \n",
    "                # Adjust for multiple testing (e.g., using Benjamini-Hochberg)\n",
    "                # This is a crucial step to avoid false positives\n",
    "                # Store raw p-values and correct later\n",
    "                current_result = {\n",
    "                    'cluster': cluster,\n",
    "                    'complex': complex_name,\n",
    "                    'overlap_genes': list(overlap),\n",
    "                    'overlap_fraction': len(overlap)/n,\n",
    "                    'raw_p_value': pval,\n",
    "                    'complex_size': K,\n",
    "                    'overlap_size': len(overlap),\n",
    "                    'cluster_size': n\n",
    "                }\n",
    "                \n",
    "                if (best_result_for_cluster is None) or (pval < best_result_for_cluster['raw_p_value']):\n",
    "                    best_result_for_cluster = current_result\n",
    "                if len(overlap) > 1:\n",
    "                    all_result.append(current_result)\n",
    "        \n",
    "        if best_result_for_cluster is not None:\n",
    "            if best_result_for_cluster['raw_p_value']<1:\n",
    "                best_result.append(best_result_for_cluster)\n",
    "    \n",
    "    # Convert results to a DataFrame for easy viewing\n",
    "    best_result_df = pd.DataFrame(best_result)\n",
    "    #best_result_df = best_result_df.sort_values(by='cluster').reset_index(drop=True)\n",
    "    all_result_df = pd.DataFrame(all_result)\n",
    "    #all_result_df = all_result_df.sort_values(by='cluster').reset_index(drop=True)\n",
    "\n",
    "    return all_result_df, best_result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8866605d-0324-4a6f-bb45-dc29aa2c45a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assess_complex_enrichment(df, complexes, cluster_label, gene_name_label):\n",
    "    \"\"\"\n",
    "    Assess pathway/complex enrichment with Benjamini-Hochberg FDR correction.\n",
    "    \"\"\"\n",
    "    de_genes_per_cluster = {}\n",
    "    clusters = df[cluster_label].unique()\n",
    "    for cluster in clusters:\n",
    "        cluster_genes = df[df[cluster_label] == cluster][gene_name_label]\n",
    "        de_genes_per_cluster[cluster] = set(cluster_genes)\n",
    "\n",
    "    N = len(df[gene_name_label].unique())\n",
    "    \n",
    "    all_result = []\n",
    "    \n",
    "    # 1. Collect all raw p-values first\n",
    "    for cluster, de_genes in de_genes_per_cluster.items():\n",
    "        n = len(de_genes)\n",
    "        \n",
    "        for complex_name, subunits in complexes.items():\n",
    "            K = len(subunits)\n",
    "            overlap = de_genes.intersection(subunits)\n",
    "            k = len(overlap)\n",
    "            \n",
    "            # Filter for non-trivial overlaps (at least 2 genes)\n",
    "            if (n > 0 and K > 0) and (k > 1): \n",
    "                pval = hypergeom.sf(k - 1, N, K, n)\n",
    "                \n",
    "                current_result = {\n",
    "                    'cluster': cluster,\n",
    "                    'complex': complex_name,\n",
    "                    'overlap_genes': list(overlap),\n",
    "                    'overlap_fraction': len(overlap)/n,\n",
    "                    'raw_p_value': pval,\n",
    "                    'complex_size': K,\n",
    "                    'overlap_size': len(overlap),\n",
    "                    'cluster_size': n\n",
    "                }\n",
    "                all_result.append(current_result)\n",
    "    \n",
    "    # 2. Create DataFrame\n",
    "    all_result_df = pd.DataFrame(all_result)\n",
    "\n",
    "    # 3. Apply FDR Correction (Benjamini-Hochberg)\n",
    "    if not all_result_df.empty:\n",
    "        # We correct across all tests performed for this specific dictionary of complexes\n",
    "        # method='fdr_bh' is the standard Benjamini-Hochberg procedure\n",
    "        rejects, fdr_pvals, _, _ = multipletests(all_result_df['raw_p_value'], alpha=0.05, method='fdr_bh')\n",
    "        all_result_df['fdr'] = fdr_pvals\n",
    "        \n",
    "        # Sort by cluster and significance\n",
    "        all_result_df = all_result_df.sort_values(by=['cluster', 'fdr', 'raw_p_value'])\n",
    "        \n",
    "        # 4. Extract best result per cluster\n",
    "        # We simply take the top hit (lowest FDR) for each cluster\n",
    "        best_result_df = all_result_df.drop_duplicates(subset=['cluster'], keep='first').copy()\n",
    "        \n",
    "        # Optional: Filter best results to only show significant ones (e.g. raw_p < 0.05 or FDR < 0.25)\n",
    "        # best_result_df = best_result_df[best_result_df['raw_p_value'] < 1] \n",
    "    else:\n",
    "        # Handle empty case\n",
    "        best_result_df = pd.DataFrame(columns=['cluster', 'complex', 'overlap_genes', 'overlap_fraction', \n",
    "                                             'raw_p_value', 'fdr', 'complex_size', 'overlap_size', 'cluster_size'])\n",
    "\n",
    "    return all_result_df, best_result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9b51b377-6a83-42ac-afa5-101655b621e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_enrichment_analysis(df, cluster_label, gene_name_label):\n",
    "    # STRINGDB enrichment\n",
    "    stringdb_enrichment_all, stringdb_enrichment_best = assess_complex_enrichment(df, stringdb_complexes, cluster_label, gene_name_label)\n",
    "    stringdb_enrichment_all = pd.merge(stringdb_enrichment_all, stringdb_df[['cluster_id', 'best_described_by']].drop_duplicates(), left_on='complex', right_on='cluster_id')\n",
    "    stringdb_enrichment_all = stringdb_enrichment_all.drop(columns=['cluster_id'])\n",
    "    stringdb_enrichment_best = pd.merge(stringdb_enrichment_best, stringdb_df[['cluster_id', 'best_described_by']].drop_duplicates(), left_on='complex', right_on='cluster_id')\n",
    "    stringdb_enrichment_best = stringdb_enrichment_best.drop(columns=['cluster_id'])\n",
    "    # Corum enrichment\n",
    "    corum_enrichment_all, corum_enrichment_best = assess_complex_enrichment(df, corum_complexes, cluster_label, gene_name_label)\n",
    "    # KEGG enrichment\n",
    "    kegg_enrichment_all, kegg_enrichment_best = assess_complex_enrichment(df, kegg_gene_sets, cluster_label, gene_name_label)\n",
    "    # Reactome enrichment\n",
    "    reactome_enrichment_all, reactome_enrichment_best = assess_complex_enrichment(df, reactome_gene_sets, cluster_label, gene_name_label)\n",
    "    \n",
    "    # Also checking inter-cluster overlap\n",
    "    gene_grouping = {}\n",
    "    gene_grouping_df = {}\n",
    "    for cluster in df[cluster_label].unique():\n",
    "        gene_grouping[cluster] = set(df[df[cluster_label]==cluster][gene_name_label])\n",
    "        gene_grouping_df[cluster] = [set(df[df[cluster_label]==cluster][gene_name_label])]\n",
    "    gene_grouping_df = pd.DataFrame(gene_grouping_df).T.rename(columns={0:'cluster_member'})\n",
    "    gene_grouping_df['cluster'] = gene_grouping_df.index\n",
    "    \n",
    "    intercluster_enrichment_all, _ = assess_complex_enrichment(df, gene_grouping, cluster_label, gene_name_label)\n",
    "    intercluster_enrichment_all = intercluster_enrichment_all[intercluster_enrichment_all.cluster!=intercluster_enrichment_all.complex].copy()\n",
    "    intercluster_enrichment_all = intercluster_enrichment_all[intercluster_enrichment_all.raw_p_value<1e-2].copy()\n",
    "    intercluster_enrichment_all = intercluster_enrichment_all[intercluster_enrichment_all.overlap_fraction>=0.2].copy()\n",
    "    intercluster_enrichment_summary = {}\n",
    "    \n",
    "    for cluster in intercluster_enrichment_all.cluster.unique():\n",
    "        intercluster_enrichment_summary[cluster] = set(intercluster_enrichment_all[intercluster_enrichment_all.cluster==cluster].complex)\n",
    "    \n",
    "    intercluster_enrichment_summary_df = pd.DataFrame(intercluster_enrichment_summary.items(), columns=['cluster', 'related_cluster'])\n",
    "    \n",
    "    # Summarize results\n",
    "    enrichment_df1 = pd.merge(corum_enrichment_best, stringdb_enrichment_best, on='cluster', how='outer', suffixes=('_corum', '_stringdb'))\n",
    "    enrichment_df2 = pd.merge(kegg_enrichment_best, reactome_enrichment_best, on='cluster', how='outer', suffixes=('_kegg', '_reactome'))\n",
    "    enrichment_df = pd.merge(enrichment_df1, enrichment_df2, on='cluster', how='outer')\n",
    "    enrichment_df = pd.merge(enrichment_df, gene_grouping_df, on='cluster', how='outer')\n",
    "    enrichment_df = pd.merge(enrichment_df, intercluster_enrichment_summary_df, on='cluster', how='outer')\n",
    "    #enrichment_df = pd.merge(cluster_df[['cluster', 'intracluster_corr', 'cluster_size', 'cluster_gene_size']], enrichment_df, on='cluster', how='outer')\n",
    "    \n",
    "    return enrichment_df, corum_enrichment_all, stringdb_enrichment_all, kegg_enrichment_all, reactome_enrichment_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8241d28d-cb21-4853-a952-f75b1309d1c1",
   "metadata": {},
   "source": [
    "### Check regulator enrichment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1fc28647-d57f-4199-835f-e4a369beb861",
   "metadata": {},
   "outputs": [],
   "source": [
    "enrichment_reg_df,\\\n",
    "corum_enrichment_reg_all,\\\n",
    "stringdb_enrichment_reg_all,\\\n",
    "kegg_enrichment_reg_all,\\\n",
    "reactome_enrichment_reg_all = run_enrichment_analysis(adata_final.obs[['hdbscan', 'target_contrast_gene_name_corrected']], 'hdbscan', 'target_contrast_gene_name_corrected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ead9366b-a4e5-4219-a1a3-605e183a74d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add cluster information\n",
    "enrichment_reg_df = pd.merge(cluster_df[['cluster', 'intracluster_corr', 'cluster_size', 'cluster_gene_size']], enrichment_reg_df, on='cluster', how='outer')\n",
    "# Add timepoint information\n",
    "cluster_member_with_condition = []\n",
    "for index, row in enrichment_reg_df.iterrows():\n",
    "    list1 = adata_final[adata_final.obs.hdbscan==row.cluster].obs.target_contrast_gene_name_corrected.tolist()\n",
    "    list2 = adata_final[adata_final.obs.hdbscan==row.cluster].obs.culture_condition.tolist()\n",
    "    cluster_member_with_condition.append([f\"{item1}_{item2}\" for item1, item2 in zip(list1, list2)])\n",
    "    enrichment_reg_df.loc[index, 'rest_count'] = len(adata_final[(adata_final.obs.hdbscan==row.cluster)&(adata_final.obs.culture_condition=='Rest')])\n",
    "    enrichment_reg_df.loc[index, 'stim8hr_count'] = len(adata_final[(adata_final.obs.hdbscan==row.cluster)&(adata_final.obs.culture_condition=='Stim8hr')])\n",
    "    enrichment_reg_df.loc[index, 'stim48hr_count'] = len(adata_final[(adata_final.obs.hdbscan==row.cluster)&(adata_final.obs.culture_condition=='Stim48hr')])\n",
    "    \n",
    "enrichment_reg_df['cluster_member_with_condition'] = cluster_member_with_condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "26d164a4-9cfc-4bc3-b1b4-53ee870e5bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "enrichment_reg_df.to_parquet('results/clustering_nde75ntotal50_reg.parquet')\n",
    "enrichment_reg_df.to_csv('results/clustering_nde75ntotal50_reg.csv')\n",
    "corum_enrichment_reg_all.to_parquet('results/corum_enrichment_nde75ntotal50_reg.parquet')\n",
    "corum_enrichment_reg_all.to_csv('results/corum_enrichment_nde75ntotal50_reg.csv')\n",
    "stringdb_enrichment_reg_all.to_parquet('results/stringdb_enrichment_nde75ntotal50_reg.parquet')\n",
    "stringdb_enrichment_reg_all.to_csv('results/stringdb_enrichment_nde75ntotal50_reg.csv')\n",
    "kegg_enrichment_reg_all.to_parquet('results/kegg_enrichment_nde75ntotal50_reg.parquet')\n",
    "kegg_enrichment_reg_all.to_csv('results/kegg_enrichment_nde75ntotal50_reg.csv')\n",
    "reactome_enrichment_reg_all.to_parquet('results/reactome_enrichment_nde75ntotal50_reg.parquet')\n",
    "reactome_enrichment_reg_all.to_csv('results/reactome_enrichment_nde75ntotal50_reg.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2cc5cb4-252e-4bd8-ac4b-0b1050f37fac",
   "metadata": {},
   "source": [
    "### Check downstream enrichment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3ef786a3-60ac-4661-8b5b-f0902ea10ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_downstream = pd.read_csv('../../../../3_expts/processed_data/analysis_largefiles/nde75ntotal50_varfiltered_simple_clustering_downstream_genes.csv', index_col=0)\n",
    "df_downstream_top = df_downstream[(df_downstream['zscore_rank_negative_regulation']<50)|(df_downstream['zscore_rank_positive_regulation']<50)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7668ebf0-5171-453e-beab-27c612ea747b",
   "metadata": {},
   "outputs": [],
   "source": [
    "enrichment_downstream_df,\\\n",
    "corum_enrichment_downstream_all,\\\n",
    "stringdb_enrichment_downstream_all,\\\n",
    "kegg_enrichment_downstream_all,\\\n",
    "reactome_enrichment_downstream_all = run_enrichment_analysis(df_downstream_top, 'hdbscan_cluster', 'downstream_gene')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5ec9d74f-a81e-406e-b21d-47a50c67f1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add timepoint information\n",
    "cluster_member_with_condition = []\n",
    "for index, row in enrichment_downstream_df.iterrows():\n",
    "    list1 = adata_final[adata_final.obs.hdbscan==row.cluster].obs.target_contrast_gene_name_corrected.tolist()\n",
    "    list2 = adata_final[adata_final.obs.hdbscan==row.cluster].obs.culture_condition.tolist()\n",
    "    cluster_member_with_condition.append([f\"{item1}_{item2}\" for item1, item2 in zip(list1, list2)])\n",
    "    enrichment_downstream_df.loc[index, 'rest_count'] = len(adata_final[(adata_final.obs.hdbscan==row.cluster)&(adata_final.obs.culture_condition=='Rest')])\n",
    "    enrichment_downstream_df.loc[index, 'stim8hr_count'] = len(adata_final[(adata_final.obs.hdbscan==row.cluster)&(adata_final.obs.culture_condition=='Stim8hr')])\n",
    "    enrichment_downstream_df.loc[index, 'stim48hr_count'] = len(adata_final[(adata_final.obs.hdbscan==row.cluster)&(adata_final.obs.culture_condition=='Stim48hr')])\n",
    "    \n",
    "enrichment_downstream_df['cluster_member_with_condition'] = cluster_member_with_condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "29e3c219-d024-4bde-b3e0-b3e401837d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "enrichment_downstream_df.to_parquet('results/clustering_nde75ntotal50_downstream.parquet')\n",
    "enrichment_downstream_df.to_csv('results/clustering_nde75ntotal50_downstream.csv')\n",
    "corum_enrichment_downstream_all.to_parquet('results/corum_enrichment_nde75ntotal50_downstream.parquet')\n",
    "corum_enrichment_downstream_all.to_csv('results/corum_enrichment_nde75ntotal50_downstream.csv')\n",
    "stringdb_enrichment_downstream_all.to_parquet('results/stringdb_enrichment_nde75ntotal50_downstream.parquet')\n",
    "stringdb_enrichment_downstream_all.to_csv('results/stringdb_enrichment_nde75ntotal50_downstream.csv')\n",
    "kegg_enrichment_downstream_all.to_parquet('results/kegg_enrichment_nde75ntotal50_downstream.parquet')\n",
    "kegg_enrichment_downstream_all.to_csv('results/kegg_enrichment_nde75ntotal50_downstream.csv')\n",
    "reactome_enrichment_downstream_all.to_parquet('results/reactome_enrichment_nde75ntotal50_downstream.parquet')\n",
    "reactome_enrichment_downstream_all.to_csv('results/reactome_enrichment_nde75ntotal50_downstream.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b6f82f82-e921-4c70-ae2e-0f2f1acf023c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# top_perc = 0.025\n",
    "\n",
    "# df_downstream_neg300 = pd.DataFrame()\n",
    "# for cl in adata_final.obs.hdbscan.unique():\n",
    "#     rank_cutoff = len(df_downstream[df_downstream.hdbscan_cluster==cl])*top_perc\n",
    "#     df_temp = df_downstream[(df_downstream.hdbscan_cluster==cl)&(df_downstream['zscore_rank_negative_regulation']<rank_cutoff)].copy()\n",
    "#     df_downstream_neg300 = pd.concat([df_downstream_neg300, df_temp])\n",
    "\n",
    "# enrichment_downstream_neg300_df,\\\n",
    "# corum_enrichment_downstream_neg300_all,\\\n",
    "# stringdb_enrichment_downstream_neg300_all,\\\n",
    "# kegg_enrichment_downstream_neg300_all,\\\n",
    "# reactome_enrichment_downstream_neg300_all,\\\n",
    "# zhang_enrichment_downstream_neg300_all,\\\n",
    "# zhang_pairwise_enrichment_downstream_neg300_all = run_enrichment_analysis(df_downstream_neg300, 'hdbscan_cluster', 'downstream_gene')\n",
    "# enrichment_downstream_neg300_df.to_csv('results/clustering_nde75ntotal50_downstream_neg300.csv')\n",
    "# corum_enrichment_downstream_neg300_all.to_csv('results/corum_enrichment_nde75ntotal50_downstream_neg300.csv')\n",
    "# stringdb_enrichment_downstream_neg300_all.to_csv('results/stringdb_enrichment_nde75ntotal50_downstream_neg300.csv')\n",
    "# kegg_enrichment_downstream_neg300_all.to_csv('results/kegg_enrichment_nde75ntotal50_downstream_neg300.csv')\n",
    "# reactome_enrichment_downstream_neg300_all.to_csv('results/reactome_enrichment_nde75ntotal50_downstream_neg300.csv')\n",
    "# zhang_enrichment_downstream_neg300_all.to_csv('results/zhang_enrichment_nde75ntotal50_downstream_neg300.csv')\n",
    "# zhang_pairwise_enrichment_downstream_neg300_all.to_csv('results/zhang_pairwise_enrichment_nde75ntotal50_downstream_neg300.csv')\n",
    "\n",
    "# df_downstream_pos300 = pd.DataFrame()\n",
    "# for cl in adata_final.obs.hdbscan.unique():\n",
    "#     rank_cutoff = len(df_downstream[df_downstream.hdbscan_cluster==cl])*top_perc\n",
    "#     df_temp = df_downstream[(df_downstream.hdbscan_cluster==cl)&(df_downstream['zscore_rank_positive_regulation']<rank_cutoff)].copy()\n",
    "#     df_downstream_pos300 = pd.concat([df_downstream_pos300, df_temp])\n",
    "    \n",
    "# enrichment_downstream_pos300_df,\\\n",
    "# corum_enrichment_downstream_pos300_all,\\\n",
    "# stringdb_enrichment_downstream_pos300_all,\\\n",
    "# kegg_enrichment_downstream_pos300_all,\\\n",
    "# reactome_enrichment_downstream_pos300_all,\\\n",
    "# zhang_enrichment_downstream_pos300_all,\\\n",
    "# zhang_pairwise_enrichment_downstream_pos300_all = run_enrichment_analysis(df_downstream_pos300, 'hdbscan_cluster', 'downstream_gene')\n",
    "# enrichment_downstream_pos300_df.to_csv('results/clustering_nde75ntotal50_downstream_pos300.csv')\n",
    "# corum_enrichment_downstream_pos300_all.to_csv('results/corum_enrichment_nde75ntotal50_downstream_pos300.csv')\n",
    "# stringdb_enrichment_downstream_pos300_all.to_csv('results/stringdb_enrichment_nde75ntotal50_downstream_pos300.csv')\n",
    "# kegg_enrichment_downstream_pos300_all.to_csv('results/kegg_enrichment_nde75ntotal50_downstream_pos300.csv')\n",
    "# reactome_enrichment_downstream_pos300_all.to_csv('results/reactome_enrichment_nde75ntotal50_downstream_pos300.csv')\n",
    "# zhang_enrichment_downstream_pos300_all.to_csv('results/zhang_enrichment_nde75ntotal50_downstream_pos300.csv')\n",
    "# zhang_pairwise_enrichment_downstream_pos300_all.to_csv('results/zhang_pairwise_enrichment_nde75ntotal50_downstream_pos300.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012391bd-418d-4d32-8c41-eb1730ddbca1",
   "metadata": {},
   "source": [
    "### Combined regulator and downstream enrichment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f8efdf8b-0c70-48be-af6e-37c34a2382f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "enrichment_reg_df, _, _, _, _ = run_enrichment_analysis(adata_final.obs[['hdbscan', 'target_contrast_gene_name_corrected']], 'hdbscan', 'target_contrast_gene_name_corrected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "72a44034-2557-4ab5-af76-467c0ef13e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "enrichment_downstream_df, _, _, _, _ = run_enrichment_analysis(df_downstream_top, 'hdbscan_cluster', 'downstream_gene')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cfb32b15-c350-4d7d-9d78-a864fd29aabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "enrichment_df = pd.merge(enrichment_reg_df, enrichment_downstream_df, how='outer', on='cluster', suffixes=('_reg', '_downstream'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "10baa999-b9ec-4589-b3e5-02e76f4aafda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add cluster information\n",
    "enrichment_df = pd.merge(cluster_df[['cluster', 'intracluster_corr', 'cluster_size', 'cluster_gene_size']], enrichment_df, on='cluster', how='outer')\n",
    "# Add timepoint information\n",
    "cluster_member_with_condition = []\n",
    "for index, row in enrichment_df.iterrows():\n",
    "    list1 = adata_final[adata_final.obs.hdbscan==row.cluster].obs.target_contrast_gene_name_corrected.tolist()\n",
    "    list2 = adata_final[adata_final.obs.hdbscan==row.cluster].obs.culture_condition.tolist()\n",
    "    cluster_member_with_condition.append([f\"{item1}_{item2}\" for item1, item2 in zip(list1, list2)])\n",
    "    enrichment_df.loc[index, 'rest_count'] = len(adata_final[(adata_final.obs.hdbscan==row.cluster)&(adata_final.obs.culture_condition=='Rest')])\n",
    "    enrichment_df.loc[index, 'stim8hr_count'] = len(adata_final[(adata_final.obs.hdbscan==row.cluster)&(adata_final.obs.culture_condition=='Stim8hr')])\n",
    "    enrichment_df.loc[index, 'stim48hr_count'] = len(adata_final[(adata_final.obs.hdbscan==row.cluster)&(adata_final.obs.culture_condition=='Stim48hr')])\n",
    "    \n",
    "enrichment_df['cluster_member_with_condition'] = cluster_member_with_condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "510cb379-36f8-474b-b9ab-31b7c136678c",
   "metadata": {},
   "outputs": [],
   "source": [
    "enrichment_df.to_parquet('results/clustering_nde75ntotal50_reg_and_downstream.parquet')\n",
    "enrichment_df.to_csv('results/clustering_nde75ntotal50_reg_and_downstream.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab1b42d-d957-425d-bb84-0af15a178e26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
