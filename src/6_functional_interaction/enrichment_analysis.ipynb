{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2df04f9-4030-4cc1-9d4d-c5e5213e2066",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rzhu/miniconda3/envs/deseq/lib/python3.11/site-packages/scanpy/_utils/__init__.py:33: FutureWarning: `__version__` is deprecated, use `importlib.metadata.version('anndata')` instead.\n",
      "  from anndata import __version__ as anndata_version\n",
      "/Users/rzhu/miniconda3/envs/deseq/lib/python3.11/site-packages/scanpy/__init__.py:24: FutureWarning: `__version__` is deprecated, use `importlib.metadata.version('anndata')` instead.\n",
      "  if Version(anndata.__version__) >= Version(\"0.11.0rc2\"):\n",
      "/Users/rzhu/miniconda3/envs/deseq/lib/python3.11/site-packages/scanpy/readwrite.py:16: FutureWarning: `__version__` is deprecated, use `importlib.metadata.version('anndata')` instead.\n",
      "  if Version(anndata.__version__) >= Version(\"0.11.0rc2\"):\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import scanpy as sc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import hdbscan\n",
    "from scipy.stats import hypergeom, pearsonr\n",
    "\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as mcolors \n",
    "import time\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "\n",
    "sys.path.append('../3_DE_analysis/')\n",
    "from DE_analysis_utils import *\n",
    "\n",
    "pd.set_option('display.max_rows', 100)\n",
    "sc.set_figure_params(figsize=(20, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cd7504f-01ef-460e-a2d4-a19c6194abc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_nde75_ntotal50 = pd.read_csv('../../metadata/clustering_results.csv', index_col=0)\n",
    "corr_df_all = pd.read_csv('../../../../3_expts/processed_data/analysis_largefiles/nde75ntotal50_gene_across_condition_correlation_matrix.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6cd6e8d5-8ce9-4fcb-a256-0e5b95150a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_name = []\n",
    "corr = []\n",
    "cluster_size = []\n",
    "cluster_gene_size = []\n",
    "cluster_member = []\n",
    "rest_count = []\n",
    "stim8hr_count = []\n",
    "stim48hr_count = []\n",
    "cluster_member_with_condition = []\n",
    "\n",
    "for i, cl in enumerate(cluster_nde75_ntotal50['hdbscan'].unique()):\n",
    "    df = cluster_nde75_ntotal50[cluster_nde75_ntotal50['hdbscan']==cl].copy()\n",
    "    \n",
    "    cluster_name.append(int(cl))\n",
    "    cluster_size.append(len(df))\n",
    "    cluster_gene_size.append(len(cluster_nde75_ntotal50[cluster_nde75_ntotal50['hdbscan']==cl].target_contrast_corrected.unique())) # number of unique regulator genes\n",
    "    cluster_member.append(cluster_nde75_ntotal50[cluster_nde75_ntotal50['hdbscan']==cl].target_contrast_gene_name_corrected.unique().tolist()) # identity of regulator genes\n",
    "    df_corr = corr_df_all.loc[cluster_nde75_ntotal50[cluster_nde75_ntotal50['hdbscan']==cl].index, cluster_nde75_ntotal50[cluster_nde75_ntotal50['hdbscan']==cl].index].copy()\n",
    "    np.fill_diagonal(df_corr.values, 0)\n",
    "    corr.append(np.mean(df_corr))\n",
    "\n",
    "    list1 = df['target_contrast_gene_name_corrected'].tolist()\n",
    "    list2 = df['culture_condition'].tolist()\n",
    "    cluster_member_with_condition.append([f\"{item1}_{item2}\" for item1, item2 in zip(list1, list2)])\n",
    "\n",
    "    rest_count.append(np.sum(df['culture_condition']=='Rest'))\n",
    "    stim8hr_count.append(np.sum(df['culture_condition']=='Stim8hr'))\n",
    "    stim48hr_count.append(np.sum(df['culture_condition']=='Stim48hr'))\n",
    "\n",
    "cluster_df = pd.DataFrame({'cluster': cluster_name,\n",
    "                           'intracluster_corr': corr,\n",
    "                           'cluster_size': cluster_size,\n",
    "                           'cluster_gene_size': cluster_gene_size,\n",
    "                           'cluster_member': cluster_member,\n",
    "                           'rest_count': rest_count,\n",
    "                           'stim8hr_count': stim8hr_count,\n",
    "                           'stim48hr_count': stim48hr_count,\n",
    "                           'cluster_member_with_condition': cluster_member_with_condition})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545fca96-e1f3-4511-a627-537a13e80185",
   "metadata": {},
   "source": [
    "### Pathway enrichment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89b4bee8-96ed-445c-93e1-b9e854f06876",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gseapy\n",
    "from gseapy import Msigdb\n",
    "from gseapy import barplot, dotplot\n",
    "\n",
    "msig = Msigdb()\n",
    "kegg_gene_sets = msig.get_gmt(category= 'c2.cp.kegg_legacy', dbver=\"2025.1.Hs\")\n",
    "kegg_gene_sets = {key: value for key, value in kegg_gene_sets.items() if len(value) <= 200} # filter out terms that are too broadly defined\n",
    "reactome_gene_sets = msig.get_gmt(category= 'c2.cp.reactome', dbver=\"2025.1.Hs\")\n",
    "reactome_gene_sets = {key: value for key, value in reactome_gene_sets.items() if len(value) <= 200} # filter out terms that are too broadly defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "012b20a9-df6e-4735-804b-7290d2ffd87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "corum_df = pd.read_csv('../../metadata/enrichment_database/corum_humanComplexes.txt', delimiter='\\t', index_col='complex_id')\n",
    "stringdb = pd.read_csv('../../metadata/enrichment_database/9606.clusters.proteins.v12.0.txt.gz', delimiter='\\t', compression='gzip')\n",
    "protein_info = pd.read_csv('../../metadata/enrichment_database/9606.protein.info.v12.0.txt.gz', delimiter='\\t', compression='gzip')\n",
    "cluster_info = pd.read_csv('../../metadata/enrichment_database/9606.clusters.info.v12.0.txt.gz', delimiter='\\t', compression='gzip')\n",
    "stringdb_df = pd.merge(stringdb, protein_info, left_on='protein_id', right_on='#string_protein_id')\n",
    "stringdb_df = pd.merge(stringdb_df, cluster_info, left_on='cluster_id', right_on='cluster_id')\n",
    "stringdb_df = stringdb_df[stringdb_df.cluster_size<=200].copy()\n",
    "\n",
    "corum_complexes = {}\n",
    "for _, row in corum_df.iterrows():\n",
    "    complex_name = row['complex_name']\n",
    "    subunits = set(row['subunits_gene_name'].split(';'))\n",
    "    corum_complexes[complex_name] = subunits\n",
    "corum_complexes = {key: value for key, value in corum_complexes.items() if len(value) <= 200} # filter out terms that are too broadly defined\n",
    "\n",
    "stringdb_complexes = {}\n",
    "for cluster_id in stringdb_df.cluster_id.unique():\n",
    "    stringdb_complexes[cluster_id] = set(stringdb_df[stringdb_df.cluster_id==cluster_id].preferred_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8866605d-0324-4a6f-bb45-dc29aa2c45a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assess_complex_enrichment(df, complexes, cluster_label, gene_name_label):\n",
    "    \"\"\"\n",
    "    Assess pathway/complex enrichment with Benjamini-Hochberg FDR correction.\n",
    "    \"\"\"\n",
    "    de_genes_per_cluster = {}\n",
    "    clusters = df[cluster_label].unique()\n",
    "    for cluster in clusters:\n",
    "        cluster_genes = df[df[cluster_label] == cluster][gene_name_label]\n",
    "        de_genes_per_cluster[cluster] = set(cluster_genes)\n",
    "\n",
    "    N = len(df[gene_name_label].unique())\n",
    "    \n",
    "    all_result = []\n",
    "    \n",
    "    # 1. Collect all raw p-values first\n",
    "    for cluster, de_genes in de_genes_per_cluster.items():\n",
    "        n = len(de_genes)\n",
    "        \n",
    "        for complex_name, subunits in complexes.items():\n",
    "            K = len(subunits)\n",
    "            overlap = de_genes.intersection(subunits)\n",
    "            k = len(overlap)\n",
    "            \n",
    "            # Filter for non-trivial overlaps (at least 2 genes)\n",
    "            if (n > 0 and K > 0) and (k > 1): \n",
    "                pval = hypergeom.sf(k - 1, N, K, n)\n",
    "                \n",
    "                current_result = {\n",
    "                    'cluster': cluster,\n",
    "                    'complex': complex_name,\n",
    "                    'overlap_genes': list(overlap),\n",
    "                    'overlap_fraction': len(overlap)/n,\n",
    "                    'raw_p_value': pval,\n",
    "                    'complex_size': K,\n",
    "                    'overlap_size': len(overlap),\n",
    "                    'cluster_size': n\n",
    "                }\n",
    "                all_result.append(current_result)\n",
    "            elif (n > 0 and K > 0) and (k <= 1): \n",
    "                current_result = {\n",
    "                    'cluster': cluster,\n",
    "                    'complex': complex_name,\n",
    "                    'overlap_genes': list(overlap),\n",
    "                    'overlap_fraction': len(overlap)/n,\n",
    "                    'raw_p_value': 1,\n",
    "                    'complex_size': K,\n",
    "                    'overlap_size': len(overlap),\n",
    "                    'cluster_size': n\n",
    "                }\n",
    "                all_result.append(current_result)\n",
    "    \n",
    "    # 2. Create DataFrame\n",
    "    all_result_df = pd.DataFrame(all_result)\n",
    "\n",
    "    # 3. Apply FDR Correction (Benjamini-Hochberg)\n",
    "    if not all_result_df.empty:\n",
    "        # We correct across all tests performed for this specific dictionary of complexes\n",
    "        # method='fdr_bh' is the standard Benjamini-Hochberg procedure\n",
    "        rejects, fdr_pvals, _, _ = multipletests(all_result_df['raw_p_value'], alpha=0.05, method='fdr_bh')\n",
    "        all_result_df['fdr'] = fdr_pvals\n",
    "        \n",
    "        # Sort by cluster and significance\n",
    "        all_result_df = all_result_df.sort_values(by=['cluster', 'fdr', 'raw_p_value'])\n",
    "        \n",
    "        # 4. Extract best result per cluster\n",
    "        # We simply take the top hit (lowest FDR) for each cluster\n",
    "        best_result_df = all_result_df.drop_duplicates(subset=['cluster'], keep='first').copy()\n",
    "        \n",
    "    else:\n",
    "        # Handle empty case\n",
    "        best_result_df = pd.DataFrame(columns=['cluster', 'complex', 'overlap_genes', 'overlap_fraction', \n",
    "                                             'raw_p_value', 'fdr', 'complex_size', 'overlap_size', 'cluster_size'])\n",
    "\n",
    "    return all_result_df, best_result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b51b377-6a83-42ac-afa5-101655b621e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_enrichment_analysis(df, cluster_label, gene_name_label):\n",
    "    # STRINGDB enrichment\n",
    "    stringdb_enrichment_all, stringdb_enrichment_best = assess_complex_enrichment(df, stringdb_complexes, cluster_label, gene_name_label)\n",
    "    stringdb_enrichment_all = pd.merge(stringdb_enrichment_all, stringdb_df[['cluster_id', 'best_described_by']].drop_duplicates(), left_on='complex', right_on='cluster_id')\n",
    "    stringdb_enrichment_all = stringdb_enrichment_all.drop(columns=['cluster_id'])\n",
    "    stringdb_enrichment_best = pd.merge(stringdb_enrichment_best, stringdb_df[['cluster_id', 'best_described_by']].drop_duplicates(), left_on='complex', right_on='cluster_id')\n",
    "    stringdb_enrichment_best = stringdb_enrichment_best.drop(columns=['cluster_id'])\n",
    "    # Corum enrichment\n",
    "    corum_enrichment_all, corum_enrichment_best = assess_complex_enrichment(df, corum_complexes, cluster_label, gene_name_label)\n",
    "    # KEGG enrichment\n",
    "    kegg_enrichment_all, kegg_enrichment_best = assess_complex_enrichment(df, kegg_gene_sets, cluster_label, gene_name_label)\n",
    "    # Reactome enrichment\n",
    "    reactome_enrichment_all, reactome_enrichment_best = assess_complex_enrichment(df, reactome_gene_sets, cluster_label, gene_name_label)\n",
    "\n",
    "    # Summarize results\n",
    "    enrichment_df1 = pd.merge(corum_enrichment_best, stringdb_enrichment_best, on='cluster', how='outer', suffixes=('_corum', '_stringdb'))\n",
    "    enrichment_df2 = pd.merge(kegg_enrichment_best, reactome_enrichment_best, on='cluster', how='outer', suffixes=('_kegg', '_reactome'))\n",
    "    enrichment_df = pd.merge(enrichment_df1, enrichment_df2, on='cluster', how='outer')\n",
    "    \n",
    "    return enrichment_df, corum_enrichment_all, stringdb_enrichment_all, kegg_enrichment_all, reactome_enrichment_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8241d28d-cb21-4853-a952-f75b1309d1c1",
   "metadata": {},
   "source": [
    "### Check regulator enrichment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1fc28647-d57f-4199-835f-e4a369beb861",
   "metadata": {},
   "outputs": [],
   "source": [
    "enrichment_df,\\\n",
    "corum_enrichment_all,\\\n",
    "stringdb_enrichment_all,\\\n",
    "kegg_enrichment_all,\\\n",
    "reactome_enrichment_all = run_enrichment_analysis(cluster_nde75_ntotal50[['hdbscan', 'target_contrast_gene_name_corrected']], 'hdbscan', 'target_contrast_gene_name_corrected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ead9366b-a4e5-4219-a1a3-605e183a74d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add cluster information\n",
    "enrichment_df = pd.merge(cluster_df, enrichment_df, on='cluster', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d164a4-9cfc-4bc3-b1b4-53ee870e5bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "enrichment_df.to_parquet('./results/clustering_nde75ntotal50_enrichment.parquet')\n",
    "enrichment_df.to_csv('./results/clustering_nde75ntotal50_enrichment.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4fa73d-28cf-46b0-b7ad-e9bc34e838a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
